{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "- Imports Done\n"
     ]
    }
   ],
   "source": [
    "from preprocess.arpit_v2 import *\n",
    "from preprocess.preprocess_v2 import *\n",
    "from preprocess.preprocess_v2 import preprocess\n",
    "import os\n",
    "import inspect\n",
    "import time\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "from models.LDA_multi_level import lda_model_multi_level\n",
    "from models.LDA_single_level import lda_model_single_level\n",
    "print('------------------------------------------------------')\n",
    "print('- Imports Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Imported Data\n"
     ]
    }
   ],
   "source": [
    "# DATA\n",
    "# Note that raw docs is a numpy array. \n",
    "# Example element is: \n",
    "# 'Logical Disk Free Space is low, Description: The disk C: on computer sjcphxstg02.strykercorp.com is running out of disk space. The values that exceeded the thre'\n",
    "# data_file_string = 'short_description.pkl'\n",
    "data_file_string = 'data.pkl'\n",
    "data_file = os.path.join(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))),'data',data_file_string)\n",
    "raw_docs = pickle.load(open(data_file,'rb'))\n",
    "print('- Imported Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-PROCESSING\n",
    "preprocess_steps_and_order = {\n",
    "\t'make_lowercase': [True],\n",
    "\t'punctuation_removal':[True],\n",
    "\t'whitespace_removal': [True],\n",
    "\t'store_alphanumeric': [False],\n",
    "\t'pos_removal_nltk': [True],\n",
    "\t'tokenization_nltk': [False],\n",
    "\t'lemmatization_tokenization_spacy': [True],\n",
    "\t'stopwords_removal_nltk': [True],\n",
    "\t'stopwords_removal_spacy': [False],\n",
    "\t'make_bigrams_gensim':[True, {'make_bigrams_gensim': True, 'bigrams_min_count': 10, 'bigrams_threshold': 10}],\n",
    "\t'make_trigrams_gensim':[True, {'make_trigrams_gensim': True, 'trigrams_min_count': 10, 'trigrams_threshold': 10}],\n",
    "\t'min_max_length_removal':[False, {'min_max_length_removal': False, 'mmlr_min_len': 3, 'mmlr_max_len': 50, 'mmlr_deacc': False}]\n",
    "\t}\n",
    "\n",
    "preprocess_functions = {\n",
    "\t'make_lowercase': make_lowercase,\n",
    "\t'punctuation_removal': punctuation_removal,\n",
    "\t'whitespace_removal': whitespace_removal,\n",
    "\t'store_alphanumeric': store_alphanumeric,\n",
    "\t'pos_removal_nltk': pos_removal_nltk,\n",
    "\t'tokenization_nltk': tokenization_nltk,\n",
    "\t'lemmatization_tokenization_spacy': lemmatization_tokenization_spacy,\n",
    "\t'stopwords_removal_nltk': stopwords_removal_nltk,\n",
    "\t'stopwords_removal_spacy': stopwords_removal_spacy,\n",
    "\t'make_bigrams_gensim': make_bigrams_gensim,\n",
    "\t'make_trigrams_gensim': make_trigrams_gensim,\n",
    "\t'min_max_length_removal': min_max_length_removal\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS\n",
    "models_dict = {\n",
    "\t'LDA_single_level': lda_model_single_level,\n",
    "\t'LDA_multi_level': lda_model_multi_level,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFICATIONS\n",
    "specifications = {\n",
    "\t# 'model':'LDA_single_level', # Can be LDA_multi_level\n",
    "\t'level':2,\n",
    "\t'num_topics_list_level_1':[5],\n",
    "\t'num_topics_list_level_2':[3],\n",
    "\t'num_topics_list_level_3':[1,2,3,4,5],\n",
    "\t'coherence':'c_v',\n",
    "\t'need_best_topic': True,\n",
    "\t'model_selection_metric':'coherence', # or 'perplexity',\n",
    "\t'debug':False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "- Starting preprocessing\n",
      "\n",
      "       ##### Lowercasing Done! Time Taken -  0.01073598861694336\n",
      "\n",
      "       ##### Punctuation removed! Time Taken -  0.11254620552062988\n",
      "\n",
      "       ##### Whitespace removed! Time Taken -  0.0592961311340332\n",
      "\n",
      "       ##### POS Removal Done! Time Taken -  26.301908016204834\n",
      "\n",
      "       ##### Lemmatization and Tokenization Done using Spacy! Time Taken -  48.417868852615356\n",
      "\n",
      "       ##### Stopwords Removed using NLTK! Time Taken -  0.20621681213378906\n",
      "\n",
      "       ##### Bi-Grams made using Gensim! Time Taken -  1.130192756652832\n",
      "\n",
      "       ##### Tri-Grams made using Gensim! Time Taken -  1.0745000839233398\n",
      "~~~ pre-processing done in  77.33268690109253\n",
      " \n",
      "- Creating dictionary and corpus\n"
     ]
    }
   ],
   "source": [
    "print('*****************************************************')\n",
    "print('- Starting preprocessing')\n",
    "dictionary, corpus, doc_list = preprocess(\n",
    "\t\t\t\t\t\t\t\traw_docs = raw_docs, \n",
    "\t\t\t\t\t\t\t\tpreprocess_functions = preprocess_functions, \n",
    "\t\t\t\t\t\t\t\tpreprocess_steps_and_order = preprocess_steps_and_order, \n",
    "\t\t\t\t\t\t\t\tdebug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "- Starting model training\n",
      " \n",
      "Sample data point:  ['dataset', 'transaction', 'credit', 'card', 'september', 'cardholder', 'dataset', 'transaction', 'day', 'fraud', 'transaction', 'dataset', 'class', 'fraud', 'account', 'transaction', 'input', 'variable', 'result', 'transformation', 'confidentiality', 'issue', 'feature', 'background', 'datum', 'feature', 'v28', 'component', 'pca', 'feature', 'pca', 'transaction', 'transaction', 'dataset', 'feature', 'amount', 'transaction', 'amount', 'feature', 'dependant', 'cost', 'feature', 'class', 'response', 'variable', 'value', 'case', 'fraud', 'class', 'imbalance', 'ratio', 'accuracy', 'area', 'precision', 'recall', 'curve', 'confusion', 'matrix', 'accuracy', 'classification', 'dataset', 'research', 'collaboration', 'worldline', 'machine', 'group', 'ac', 'libre', 'bruxelle', 'datum_mining', 'fraud', 'detection', 'detail', 'project', 'topic', 'http', 'mlg', 'brufence', 'http', 'mlg', 'dal', 'pozzolo', 'johnson', 'gianluca', 'bontempi', 'probability', 'classification', 'symposium', 'intelligence', 'datum_mining', 'cidm', 'ieee']\n",
      " \n",
      "\t### Running LDA for number of topic - 5\n",
      "\tLDA Done for 5 topic! Time Taken is 11.148399114608765\n",
      "\tEvaluating model for number of topic - 5\n",
      "Coherence - 0.4043487324677483, Perplexity - -8.619077748462646\n",
      "---\n",
      "\t### Running LDA for number of topic - 10\n",
      "\tLDA Done for 10 topic! Time Taken is 16.16946291923523\n",
      "\tEvaluating model for number of topic - 10\n",
      "Coherence - 0.4611216445466872, Perplexity - -9.539076388847784\n",
      "---\n",
      "\t### Running LDA for number of topic - 15\n",
      "\tLDA Done for 15 topic! Time Taken is 17.517346143722534\n",
      "\tEvaluating model for number of topic - 15\n",
      "Coherence - 0.45147719224376776, Perplexity - -13.01641728115097\n",
      "---\n",
      "\t### Running LDA for number of topic - 20\n",
      "\tLDA Done for 20 topic! Time Taken is 21.60917568206787\n",
      "\tEvaluating model for number of topic - 20\n",
      "Coherence - 0.4743907257667179, Perplexity - -14.93617255441453\n",
      "---\n",
      "\t### Running LDA for number of topic - 25\n",
      "\tLDA Done for 25 topic! Time Taken is 24.9688138961792\n",
      "\tEvaluating model for number of topic - 25\n",
      "Coherence - 0.4372140848990896, Perplexity - -16.670845026241796\n",
      "---\n",
      "- Done training model on all topics in 109.30756902694702 sec!\n",
      "Done Single-Level LDA\n"
     ]
    }
   ],
   "source": [
    "print('*****************************************************')\n",
    "print('- Starting model training')\n",
    "lda_dict = lda_model_single_level(\n",
    "\t\t\t\t\tdictionary = dictionary,\n",
    "\t\t\t\t\tcorpus = corpus,\n",
    "\t\t\t\t\tdoc_list = doc_list,\n",
    "\t\t\t\t\tnum_topics_list_level_1 = specifications['num_topics_list_level_1'], \n",
    "\t\t\t\t\tcoherence = specifications['coherence'],\n",
    "\t\t\t\t\tdebug = specifications['debug'],\n",
    "\t\t\t\t\tneed_best_topic = specifications['need_best_topic'],\n",
    "\t\t\t\t\tmodel_selection_metric = specifications['model_selection_metric']\n",
    "\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.47154971390590406\n",
      "-8.58700882191759\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "print(lda_dict['best_topic'])\n",
    "print(lda_dict['coherence_score'])\n",
    "print(lda_dict['perplexity_score'])\n",
    "visualization = pyLDAvis.gensim.prepare(lda_dict['best_lda_model'], lda_dict['corpus'], lda_dict['dictionary'])\n",
    "pyLDAvis.save_html(visualization, 'lda.html')\n",
    "visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "- Starting model training\n",
      " \n",
      "Sample data point:  ['dataset', 'transaction', 'credit', 'card', 'september', 'cardholder', 'dataset', 'transaction', 'day', 'fraud', 'transaction', 'dataset', 'class', 'fraud', 'account', 'transaction', 'input', 'variable', 'result', 'transformation', 'confidentiality', 'issue', 'feature', 'background', 'datum', 'feature', 'v28', 'component', 'pca', 'feature', 'pca', 'transaction', 'transaction', 'dataset', 'feature', 'amount', 'transaction', 'amount', 'feature', 'dependant', 'cost', 'feature', 'class', 'response', 'variable', 'value', 'case', 'fraud', 'class', 'imbalance', 'ratio', 'accuracy', 'area', 'precision', 'recall', 'curve', 'confusion', 'matrix', 'accuracy', 'classification', 'dataset', 'research', 'collaboration', 'worldline', 'machine', 'group', 'ac', 'libre', 'bruxelle', 'datum_mining', 'fraud', 'detection', 'detail', 'project', 'topic', 'http', 'mlg', 'brufence', 'http', 'mlg', 'dal', 'pozzolo', 'johnson', 'gianluca', 'bontempi', 'probability', 'classification', 'symposium', 'intelligence', 'datum_mining', 'cidm', 'ieee']\n",
      " \n",
      "### Running process for Level-1\n",
      "\t### Running LDA for number of topic - 5\n",
      "\tLDA Done for 5 topic! Time Taken is 10.629188776016235\n",
      "\tEvaluating model for number of topic - 5\n",
      "Coherence - 0.4043487324677483, Perplexity - -8.619077748462646\n",
      "---\n",
      "- Done training model for Level-1 on all topics in 12.458504915237427 sec!\n",
      "### Running process for Level-2\n",
      "~~~ Running for documents in topic 1\n",
      "\t\tRunning for topic 3\n",
      "\t\tLDA Done for 3 topic! Time Taken is 4.49990701675415\n",
      "~~~ Process done for documents in topic 1\n",
      "~~~ Running for documents in topic 2\n",
      "\t\tRunning for topic 3\n",
      "\t\tLDA Done for 3 topic! Time Taken is 0.8064069747924805\n",
      "~~~ Process done for documents in topic 2\n",
      "~~~ Running for documents in topic 3\n",
      "\t\tRunning for topic 3\n",
      "\t\tLDA Done for 3 topic! Time Taken is 1.5272400379180908\n",
      "~~~ Process done for documents in topic 3\n",
      "~~~ Running for documents in topic 4\n",
      "\t\tRunning for topic 3\n",
      "\t\tLDA Done for 3 topic! Time Taken is 0.8288571834564209\n",
      "~~~ Process done for documents in topic 4\n",
      "~~~ Running for documents in topic 5\n",
      "\t\tRunning for topic 3\n",
      "\t\tLDA Done for 3 topic! Time Taken is 4.230271100997925\n",
      "~~~ Process done for documents in topic 5\n"
     ]
    }
   ],
   "source": [
    "print('*****************************************************')\n",
    "print('- Starting model training')\n",
    "lda_level_1, lda_level_2 = lda_model_multi_level(\n",
    "\t\t\t\t\tlevel = specifications['level'],\n",
    "\t\t\t\t\tdictionary = dictionary,\n",
    "\t\t\t\t\tcorpus = corpus,\n",
    "\t\t\t\t\tdoc_list = doc_list,\n",
    "\t\t\t\t\tcoherence = specifications['coherence'],\n",
    "\t\t\t\t\tdebug = specifications['debug'],\n",
    "\t\t\t\t\tneed_best_topic = specifications['need_best_topic'],\n",
    "\t\t\t\t\tmodel_selection_metric = specifications['model_selection_metric'],\n",
    "\t\t\t\t\tnum_topics_list_level_1 = specifications['num_topics_list_level_1'], \n",
    "\t\t\t\t\tnum_topics_list_level_2 = specifications['num_topics_list_level_2'], \n",
    "\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['best_lda_model', 'best_topic', 'coherence_score', 'perplexity_score', 'corpus', 'dictionary', 'doc_list', 'all_models'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_level_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"state\" + 0.009*\"country\" + 0.007*\"city\" + 0.007*\"type\" + 0.006*\"price\" + 0.006*\"value\" + 0.006*\"service\" + 0.006*\"code\" + 0.006*\"location\" + 0.005*\"variable\"'),\n",
       " (1,\n",
       "  '0.048*\"serverruntime_i0_lphost06_type\" + 0.022*\"com_bea_name_serverruntime\" + 0.014*\"i0_lphost06_type_jdbcdatasourceruntime\" + 0.013*\"jdbcdatasourceruntime\" + 0.013*\"jdbcconnectionpoolruntime\" + 0.010*\"jdbcdatasourceruntime_com_bea_name\" + 0.010*\"wine\" + 0.008*\"review\" + 0.008*\"road\" + 0.008*\"i0_lphost06_type_jdbcconnectionpoolruntime\"'),\n",
       " (2,\n",
       "  '0.014*\"player\" + 0.013*\"movie\" + 0.011*\"team\" + 0.009*\"game\" + 0.009*\"student\" + 0.008*\"baseball\" + 0.007*\"statistic\" + 0.007*\"score\" + 0.007*\"school\" + 0.007*\"result\"'),\n",
       " (3,\n",
       "  '0.014*\"university\" + 0.011*\"image\" + 0.007*\"state_university\" + 0.004*\"kumar\" + 0.003*\"matrix\" + 0.003*\"de\" + 0.003*\"cell\" + 0.002*\"defense\" + 0.002*\"damage\" + 0.002*\"pokemon\"'),\n",
       " (4,\n",
       "  '0.009*\"user\" + 0.007*\"text\" + 0.007*\"language\" + 0.007*\"word\" + 0.006*\"corpus\" + 0.006*\"attribution_citation_research_inspiration\" + 0.006*\"community_question\" + 0.006*\"datum_front_datum_science\" + 0.006*\"project\" + 0.006*\"context_story_dataset_opportunity\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_level_1['best_lda_model'].print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_level_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"price\" + 0.007*\"company\" + 0.006*\"crime\" + 0.005*\"state\" + 0.005*\"type\" + 0.005*\"value\" + 0.005*\"vehicle\" + 0.005*\"record\" + 0.005*\"city\" + 0.004*\"location\"'),\n",
       " (1,\n",
       "  '0.011*\"state\" + 0.011*\"country\" + 0.007*\"survey\" + 0.006*\"health\" + 0.006*\"population\" + 0.006*\"people\" + 0.005*\"school\" + 0.005*\"rate\" + 0.005*\"education\" + 0.004*\"government\"'),\n",
       " (2,\n",
       "  '0.008*\"city\" + 0.007*\"csv\" + 0.005*\"customer\" + 0.004*\"station\" + 0.004*\"location\" + 0.004*\"day\" + 0.004*\"system\" + 0.004*\"-PRON-\" + 0.004*\"service\" + 0.004*\"value\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_level_2[0]['best_lda_model'].print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.035*\"serverruntime_i0_lphost06_type\" + 0.016*\"com_bea_name_serverruntime\" + 0.011*\"i0_lphost06_type_jdbcdatasourceruntime\" + 0.010*\"jdbcdatasourceruntime\" + 0.010*\"jdbcconnectionpoolruntime\" + 0.008*\"jdbcdatasourceruntime_com_bea_name\" + 0.006*\"i0_lphost06_type_jdbcconnectionpoolruntime\" + 0.005*\"jdbcconnectionpoolruntime_com_bea_name\" + 0.003*\"type_server_com_bea\" + 0.003*\"road\"'),\n",
       " (1,\n",
       "  '0.007*\"wine\" + 0.004*\"gb\" + 0.003*\"aircraft\" + 0.003*\"output\" + 0.003*\"ru\" + 0.003*\"review\" + 0.002*\"plane\" + 0.002*\"crash\" + 0.002*\"quality\" + 0.002*\"de\"'),\n",
       " (2,\n",
       "  '0.005*\"value\" + 0.004*\"airport\" + 0.004*\"state\" + 0.003*\"stop\" + 0.003*\"da\" + 0.003*\"airline\" + 0.003*\"🇧_🇷_🇬_🇧\" + 0.003*\"congressperson\" + 0.002*\"group\" + 0.002*\"bird\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_level_2[1]['best_lda_model'].print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.008*\"movie\" + 0.006*\"horse\" + 0.004*\"dt\" + 0.003*\"place\" + 0.002*\"simadi\" + 0.002*\"dolartoday\" + 0.002*\"imdb\" + 0.002*\"employer\" + 0.002*\"film\" + 0.002*\"box_office\"'),\n",
       " (1,\n",
       "  '0.006*\"model\" + 0.006*\"network\" + 0.006*\"pre_model_pre_model\" + 0.005*\"layer\" + 0.005*\"feature\" + 0.004*\"architecture\" + 0.004*\"accuracy\" + 0.004*\"representation\" + 0.003*\"depth\" + 0.003*\"imagenet\"'),\n",
       " (2,\n",
       "  '0.020*\"player\" + 0.014*\"team\" + 0.013*\"game\" + 0.009*\"match\" + 0.007*\"point\" + 0.005*\"integer\" + 0.005*\"com\" + 0.005*\"movie\" + 0.005*\"csv\" + 0.005*\"result\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_level_2[2]['best_lda_model'].print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
